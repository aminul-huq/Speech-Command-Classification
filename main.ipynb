{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ah8VNBm5o93H"},"outputs":[],"source":["import os, warnings\n","import numpy as np\n","import matplotlib.pyplot as plt\n","warnings.filterwarnings(\"ignore\")\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader,random_split,Dataset\n","import torchaudio\n","from torchaudio import transforms\n","from torch import Tensor\n","from torchaudio.datasets.utils import (\n","    download_url,\n","    extract_archive,\n","    walk_files\n",")\n","\n","from train_utils import *\n","from model import *\n","from dataloader import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTcTT8A-o93P"},"outputs":[],"source":["train_audio_path = './data1/SpeechCommands/speech_commands_v0.02/'\n","\n","labels_dict=os.listdir(train_audio_path)\n","\n","a = torchaudio.datasets.SPEECHCOMMANDS('./data1/' , url = 'speech_commands_v0.02', \n","                                       folder_in_archive= 'SpeechCommands', download = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BuftEzk2o93Q"},"outputs":[],"source":["filename = \"./data1/SpeechCommands/speech_commands_v0.02/backward/0165e0e8_nohash_0.wav\"\n","waveform, sample_rate = torchaudio.load(filename)\n","\n","print(\"Shape of waveform: {}\".format(waveform.size()))\n","print(\"Sample rate of waveform: {}\".format(sample_rate))\n","\n","plt.figure()\n","plt.plot(waveform.t().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w9Ya04G0o93R"},"outputs":[],"source":["plt.plot(a[0][0].t())\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZR7Rlw6No93S"},"outputs":[],"source":["count=0\n","wave = []\n","labels = []\n","for i in range(0,105829):\n","    if a[i][0].shape == (1,16000):\n","        wave.append(a[i][0])\n","        labels.append(a[i][2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VN6kcU3mo93U"},"outputs":[],"source":["specgram = torchaudio.transforms.MFCC()(wave[0])\n","\n","print(\"Shape of spectrogram: {}\".format(specgram.size()))\n","\n","plt.figure(figsize=(10,5))\n","plt.imshow(specgram[0,:,:].numpy())\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4aardBrqo93V"},"outputs":[],"source":["specgram = torchaudio.transforms.MelSpectrogram()(wave[0])\n","mfcc = torchaudio.transforms.MFCC()(wave[0])\n","\n","\n","fig,ax = plt.subplots(1,2)\n","\n","ax[0].imshow(specgram[0,:,:].numpy())\n","ax[1].imshow(mfcc[0,:,:].numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNhxe6vEo93W"},"outputs":[],"source":["data_transform = 0\n","\n","if data_transform == 1:\n","    print(\"MFCC Features classification\")\n","    train_audio_transforms = nn.Sequential(\n","            torchaudio.transforms.MFCC(log_mels=False)\n","            )\n","    net = NN2D(num_class=35)\n","elif data_transform == 2:\n","    print(\"Mel Spectogram Features classification\")\n","    train_audio_transforms = nn.Sequential(\n","            torchaudio.transforms.MelSpectrogram()\n","            )\n","    net = NN2DMEL(num_class=35)\n","else:\n","    train_audio_transforms = None\n","    net = NN(num_class=35)"]},{"cell_type":"code","source":["labels_dict=list(set(labels))"],"metadata":{"id":"CpmLFQPWpFlV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmvFlZ-Ro93X"},"outputs":[],"source":["dataset= SpeechDataLoader(wave,labels,labels_dict, train_audio_transforms)\n","\n","traindata, testdata = random_split(dataset, [round(len(dataset)*.8), round(len(dataset)*.2)])\n","\n","trainloader = torch.utils.data.DataLoader(traindata, batch_size=100, shuffle=True)\n","\n","testloader = torch.utils.data.DataLoader(testdata, batch_size=100, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YefK0_4o93Y"},"outputs":[],"source":["device = torch.device('cuda:9' if torch.cuda.is_available() else 'cpu')\n","\n","net = net.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n","                                              steps_per_epoch=int(len(trainloader)),\n","                                              epochs=num_epochs,\n","                                              anneal_strategy='linear') \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePBxi5pno93Z"},"outputs":[],"source":["num_epochs=20\n","\n","for epoch in range(0, num_epochs):\n","    \n","    train(net,trainloader,optimizer,scheduler,criterion,epoch,device)\n","    best_acc = test(net,testloader,optimizer,criterion,epoch,device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uF8eqS7Po93Z"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:pyTorch]","language":"python","name":"conda-env-pyTorch-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}